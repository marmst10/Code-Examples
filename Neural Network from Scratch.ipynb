{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network from Scratch\n",
    "## STAT 7900 - Python for Data Science\n",
    "## Spring 2021\n",
    "### Connor Armstrong\n",
    "### May 5th, 2021\n",
    "This notebook contains code for a class which can be used to train a neural network with one or two hidden layers to predict binary data (labels, result) from binary descriptors (features). The class contains several functions with inputs that can be selected by the user. The following is a definition of the inputs to class initialization and functions:\n",
    "\n",
    "#### Initialization\n",
    "&nbsp; \"features\" - 2-dimensional numpy array of features data with column of 1's in the first column<br>\n",
    "&nbsp; \"result\" - 1-dimensional numpy array of label data<br>\n",
    "&nbsp; \"batchsize\" - integer, amount of observations to be evaluated at a time within the \"fit\" function<br>\n",
    "&nbsp; \"h1\" - number of nodes in the hidden layer (1), second layer if num_hidden_layers = 2<br>\n",
    "&nbsp; \"h2\" - if two hidden layers are specified by the user, the number of nodes in the first hidden layer (2). Default = 5<br>\n",
    "&nbsp; \"num_hidden_layers\" - User specifies 1 or 2 for one hidden layer or two hidden layers. Default = 1<br>\n",
    "\n",
    "#### \"fit\" function\n",
    "&nbsp; \"num_iterations\" - integer, number of passes through the model<br>\n",
    "&nbsp; \"learning_rate\" - float, learning rate variable multiplied to weight gradients at each iteration<br>\n",
    "&nbsp; \"out_freq\" - integer, frequency at which model performance statistics are printed. Default = 10 <br>\n",
    "&nbsp; \"stifle\" - boolean, user specifies whether printed output is desired. Helpful when iterating through the class many times. Default = False<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                             #array manipulation\n",
    "import collections                             #frequency counter\n",
    "from sklearn import svm                        #import a1a dataset\n",
    "from sklearn.datasets import load_svmlight_file#import a1a dataset\n",
    "from sklearn.utils import shuffle              #for batching \n",
    "import pandas as pd                            #for model performance and grid search dataframes\n",
    "import random                                  #for random sample\n",
    "import math                                    #floor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Define Neural Network Class and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid Function\n",
    "def sig(x):\n",
    "    out = 1/(1+np.exp(-x))\n",
    "    return out\n",
    "\n",
    "#Neural Network class with one or two hidden layers\n",
    "class neural_network:\n",
    "    def __init__(self, features, result, batchsize, h1, h2=5, num_hidden_layers=1):\n",
    "        self.inputx = features\n",
    "        self.inputy = np.squeeze(result)\n",
    "        self.batchsize1 = batchsize\n",
    "        self.num_hidden_layers1 = num_hidden_layers\n",
    "        h21 = h2  #number of nodes in first hidden layer W2\n",
    "        h11 = h1  #number of nodes in second hidden layer W1 (OR FIRST HIDDEN LAYER IF ONE LAYER NN)\n",
    "        self.names = [\"Step\", \"Number Correct\", \"MSE\", \"Accuracy\"]#model performance dataframe column names\n",
    "\n",
    "        if self.num_hidden_layers1 == 2:\n",
    "            W2_number = self.inputx.shape[1]*h2#features includes column of ones, so features.shape[1] = p+1\n",
    "            W1_number = (h21+1)*h11\n",
    "            self.W2 = np.array(np.random.standard_normal((self.inputx.shape[1],h21)))#*((2/self.batchsize1)**0.5))\n",
    "            #dimensions are (# features + 1, h2)\n",
    "            \n",
    "            self.W1 = np.array(np.random.standard_normal((h21+1,h11)))#*((2/self.batchsize1)**0.5))\n",
    "            #dimensions are (h2 + 1, h1)\n",
    "            \n",
    "        elif self.num_hidden_layers1 == 1:\n",
    "            W1_number = self.inputx.shape[1]*h11\n",
    "            self.W1 = np.array(np.random.standard_normal((self.inputx.shape[1],h11))*((2/self.batchsize1)**0.5))\n",
    "        self.W0 = np.random.standard_normal(h1+1)*((2/(batchsize+1))**0.5)#dim (h1+1,)\n",
    "        \n",
    "    def fit(self, num_iterations, learning_rate, out_freq = 10, stifle = False):#consider using verbose 0 is everything, 1 is only important, 2 is nothing\n",
    "        #initial user feedback\n",
    "        if stifle == False and self.num_hidden_layers1 == 1:\n",
    "            print(\"Training Neural Network with 1 Hidden-Layer\\n\")\n",
    "        elif stifle == False and self.num_hidden_layers1 == 2:\n",
    "            print(\"Training Neural Network with 2 Hidden-Layers\\n\")\n",
    "            \n",
    "        #begin training model\n",
    "        for x in range(num_iterations):\n",
    "            shuffle_x, shuffle_y = shuffle(self.inputx, self.inputy, random_state=None)\n",
    "            for i in np.arange(0, shuffle_x.shape[0], self.batchsize1):\n",
    "                batch_x = shuffle_x[i:i+self.batchsize1]\n",
    "                batch_y = np.squeeze(shuffle_y[i:i+self.batchsize1])\n",
    "                if self.num_hidden_layers1 == 2:\n",
    "                    X = np.matmul(batch_x, self.W2)                \n",
    "                    Y2 =  (np.c_[np.ones(X.shape[0]), sig(X)])     \n",
    "                    Hidden = np.matmul(Y2,self.W1)                 \n",
    "                    Y1 =  (np.c_[np.ones(X.shape[0]), sig(Hidden)])\n",
    "                elif self.num_hidden_layers1 == 1:\n",
    "                    X = np.matmul(batch_x, self.W1)                \n",
    "                    Y1 =  (np.c_[np.ones(X.shape[0]), sig(X)])     \n",
    "                Yhat = sig(np.matmul(Y1, self.W0))             \n",
    "                delta_W0 = 2*np.dot((Yhat-batch_y)*Yhat*(1-Yhat), Y1)\n",
    "                hidden_element = np.einsum(\"ij, j -> ij\",np.einsum(\"i, ij -> ij\",(Yhat-batch_y)*Yhat*(1-Yhat),Y1[:,1:]*(1-Y1[:,1:])),self.W0[1:])   \n",
    "                if self.num_hidden_layers1 == 2:\n",
    "                    delta_W1 = 2*np.matmul(Y2.T, hidden_element) \n",
    "                    delta_W2 = 2*np.matmul(batch_x.T,np.einsum(\"ij,ij -> ij\",np.matmul(hidden_element,self.W1[1:].T),Y2[:,1:]*(1-Y2[:,1:])))\n",
    "                    self.W2 = self.W2 - learning_rate * delta_W2    \n",
    "                elif self.num_hidden_layers1 == 1:\n",
    "                    delta_W1 = 2*np.matmul(batch_x.T, hidden_element)\n",
    "                self.W0 = self.W0 - learning_rate * delta_W0\n",
    "                self.W1 = self.W1 - learning_rate * delta_W1\n",
    "            #to print model performance statistics while fitting model\n",
    "            if x % out_freq == 0 and stifle == False and x != num_iterations and x != 0:\n",
    "                if self.num_hidden_layers1 == 2:\n",
    "                    X1 = np.matmul(self.inputx, self.W2)                                           \n",
    "                    Y11 =  (np.c_[np.ones(X1.shape[0]), sig(np.matmul((np.c_[np.ones(X1.shape[0]), sig(X1)]),self.W1))])\n",
    "                if self.num_hidden_layers1 == 1:\n",
    "                    X1 = np.matmul(self.inputx, self.W1)                     \n",
    "                    Y11 =  (np.c_[np.ones(X1.shape[0]), sig(X1)])\n",
    "                Yhat1 = sig(np.matmul(Y11, self.W0))   \n",
    "                MSE = (1/(2*len(self.inputy)))*sum((Yhat1-self.inputy)**2)\n",
    "                number_correct = sum(np.round(Yhat1) == self.inputy)\n",
    "                accuracy = 100*number_correct/len(self.inputy)\n",
    "                mod_perf_list = [(x, number_correct, MSE, accuracy)]\n",
    "                print(pd.DataFrame(mod_perf_list, columns = self.names))#print individual values of dataframe ie mod_perf_list.MSE\n",
    "                print()\n",
    "        \n",
    "        #calculate final performance statistics\n",
    "        if self.num_hidden_layers1 == 2:\n",
    "            self.X = np.matmul(self.inputx, self.W2)                   \n",
    "            Y2 =  (np.c_[np.ones(self.X.shape[0]), sig(self.X)])     \n",
    "            Hidden = np.matmul(Y2,self.W1)                       \n",
    "            Y1 =  (np.c_[np.ones(self.X.shape[0]), sig(Hidden)])\n",
    "        if self.num_hidden_layers1 == 1:\n",
    "            self.X = np.matmul(self.inputx, self.W1)                     \n",
    "            Y1 =  (np.c_[np.ones(self.X.shape[0]), sig(self.X)])\n",
    "        self.Yhat = sig(np.matmul(Y1, self.W0))                  \n",
    "    \n",
    "        #modelevalparams, put them here so can be accessed without running model_eval\n",
    "        self.MSE = (1/(2*len(self.inputy)))*sum((self.Yhat-self.inputy)**2)\n",
    "        self.MAE = sum(abs(self.Yhat-self.inputy))/len(self.inputy)\n",
    "        self.number_predicted = sum(np.round(self.Yhat))\n",
    "        self.number_correct = sum(np.round(self.Yhat) == self.inputy)\n",
    "        self.accuracy = 100*self.number_correct/len(self.inputy)\n",
    "         \n",
    "        \n",
    "        #model_eval\n",
    "        if stifle == False:\n",
    "            if self.num_hidden_layers1 == 1:\n",
    "                print(\"\\nNeural Network with 1 Hidden-Layer Complete\\n\")\n",
    "            elif self.num_hidden_layers1 == 2:\n",
    "                print(\"\\nNeural Network with 2 Hidden-Layers Complete\\n\")\n",
    "            print(\"Final Performance Metrics after\", num_iterations, \"iterations:\\n\")\n",
    "            print(\"MSE: \",\"{:.3f}\".format(self.MSE))\n",
    "            print(\"Mean Absolute Error: \",\"{:.3f}\".format(self.MAE))\n",
    "            print(self.number_correct,\"/\",len(self.inputy),\" predicted correctly -> \",\"{:.1f}\".format(self.accuracy),\"% accuracy\")\n",
    "        \n",
    "    def predict(self, test_x, test_y, stifle = False):\n",
    "        if self.num_hidden_layers1 == 2:\n",
    "            self.X = np.matmul(test_x, self.W2)                   \n",
    "            Y2 =  (np.c_[np.ones(self.X.shape[0]), sig(self.X)])     \n",
    "            Hidden = np.matmul(Y2,self.W1)                       \n",
    "            Y1 =  (np.c_[np.ones(self.X.shape[0]), sig(Hidden)])\n",
    "        if self.num_hidden_layers1 == 1:\n",
    "            self.X = np.matmul(test_x, self.W1)                     \n",
    "            Y1 =  (np.c_[np.ones(self.X.shape[0]), sig(self.X)])\n",
    "        self.Yhat = sig(np.matmul(Y1, self.W0))\n",
    "        self.MSE = (1/(2*len(test_y)))*sum((self.Yhat-test_y)**2)\n",
    "        self.MAE = sum(abs(self.Yhat-test_y))/len(test_y)\n",
    "        self.number_predicted = sum(np.round(self.Yhat))\n",
    "        self.number_correct = sum(np.round(self.Yhat) == test_y)\n",
    "        self.accuracy = 100*self.number_correct/len(test_y)\n",
    "        if stifle == False:\n",
    "            if self.num_hidden_layers1 == 1:\n",
    "                print(\"\\nNeural Network with 1 Hidden-Layer Prediction\\n\")\n",
    "            elif self.num_hidden_layers1 == 2:\n",
    "                print(\"\\nNeural Network with 2 Hidden-Layers Prediction\\n\")\n",
    "            print(\"MSE: \",\"{:.3f}\".format(self.MSE))\n",
    "            print(\"Mean Absolute Error: \",\"{:.3f}\".format(self.MAE))\n",
    "            print(self.number_correct,\"/\",len(test_y),\" predicted correctly -> \",\"{:.1f}\".format(self.accuracy),\"% accuracy\")\n",
    "        return self.Yhat\n",
    "    def score(self, test_x, test_y):\n",
    "        SSE = sum((self.predict(test_x, test_y) - test_y)**2)\n",
    "        SSM = sum((test_y - np.mean(test_y))**2)\n",
    "        return 1 - SSE/SSM\n",
    "    def coef(self):\n",
    "        if self.num_hidden_layers1 == 2:\n",
    "            print(\"W0\", self.W0, \"\\n\")\n",
    "            print(\"W1\", self.W1, \"\\n\")\n",
    "            print(\"W2\", self.W2, \"\\n\")\n",
    "        if self.num_hidden_layers1 == 1:\n",
    "            print(\"W0\", self.W0, \"\\n\")\n",
    "            print(\"W1\", self.W1, \"\\n\")\n",
    "#method returns 2 data objects for input and output, to import a1a data\n",
    "def get_data(datafile):\n",
    "    data = load_svmlight_file(datafile)\n",
    "    return data[0], data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Import and Prepare a1a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Z = get_data('C:/Users/conno/OneDrive/Desktop/STAT 7900 - Python for Data Science/Project/a1a.txt')\n",
    "\n",
    "#X is sparse matrix\n",
    "denseX = X.todense()\n",
    "arrayX = np.squeeze(np.asarray(denseX))\n",
    "\n",
    "#Convert -1's to 0's\n",
    "Z_01 = Z\n",
    "for x in range(0, Z.shape[0]):\n",
    "    if Z_01[x] == -1:\n",
    "            Z_01[x] = 0\n",
    "            \n",
    "#define inputs to model\n",
    "a1a_x = np.hstack((np.ones((arrayX.shape[0],1)),arrayX))\n",
    "a1a_y = Z_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Simple One-Hidden-Layer Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Neural Network with 1 Hidden-Layer\n",
      "\n",
      "\n",
      "Neural Network with 1 Hidden-Layer Complete\n",
      "\n",
      "Final Performance Metrics after 100 iterations:\n",
      "\n",
      "MSE:  0.049\n",
      "Mean Absolute Error:  0.005\n",
      "1400 / 1605  predicted correctly ->  87.2 % accuracy\n"
     ]
    }
   ],
   "source": [
    "test = neural_network(features=a1a_x, result=a1a_y, batchsize=20, h1=13, num_hidden_layers=1)\n",
    "test.fit(num_iterations = 100, learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Simple Two-Hidden-Layer Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Neural Network with 2 Hidden-Layers\n",
      "\n",
      "\n",
      "Neural Network with 2 Hidden-Layers Complete\n",
      "\n",
      "Final Performance Metrics after 100 iterations:\n",
      "\n",
      "MSE:  0.048\n",
      "Mean Absolute Error:  0.000\n",
      "1397 / 1605  predicted correctly ->  87.0 % accuracy\n"
     ]
    }
   ],
   "source": [
    "test2 = neural_network(features=a1a_x, result=a1a_y, batchsize=20, h1=13, h2=5, num_hidden_layers=2)\n",
    "test2.fit(num_iterations = 100, learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Demonstrate \"stifle\" and Calling Parameters Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.1619937694704\n",
      "1415\n"
     ]
    }
   ],
   "source": [
    "test2.fit(num_iterations = 100, learning_rate = 0.01, stifle = True)\n",
    "print(test2.accuracy)\n",
    "print(test2.number_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Demonstrate use of user-defined print interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Neural Network with 2 Hidden-Layers\n",
      "\n",
      "   Step  Number Correct       MSE  Accuracy\n",
      "0    20            1452  0.038905  90.46729\n",
      "\n",
      "   Step  Number Correct       MSE   Accuracy\n",
      "0    40            1458  0.036938  90.841121\n",
      "\n",
      "   Step  Number Correct       MSE   Accuracy\n",
      "0    60            1468  0.035446  91.464174\n",
      "\n",
      "   Step  Number Correct       MSE   Accuracy\n",
      "0    80            1464  0.034593  91.214953\n",
      "\n",
      "\n",
      "Neural Network with 2 Hidden-Layers Complete\n",
      "\n",
      "Final Performance Metrics after 100 iterations:\n",
      "\n",
      "MSE:  0.033\n",
      "Mean Absolute Error:  0.014\n",
      "1478 / 1605  predicted correctly ->  92.1 % accuracy\n"
     ]
    }
   ],
   "source": [
    "test2.fit(num_iterations = 100, learning_rate = 0.01, out_freq=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Define Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1284, 120)\n",
      "(321, 120)\n",
      "(1284,)\n",
      "(321,)\n"
     ]
    }
   ],
   "source": [
    "test_number = math.floor(a1a_x.shape[0]*0.20)\n",
    "a1a_x_train, a1a_x_test, a1a_y_train, a1a_y_test = train_test_split(a1a_x, a1a_y, test_size=test_number)\n",
    "print(a1a_x_train.shape)\n",
    "print(a1a_x_test.shape)\n",
    "print(a1a_y_train.shape)\n",
    "print(a1a_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Train and Test Neural Network with 1 Hidden-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network with 1 Hidden-Layer Prediction\n",
      "\n",
      "MSE:  0.057\n",
      "Mean Absolute Error:  0.006\n",
      "267 / 321  predicted correctly ->  83.2 % accuracy\n"
     ]
    }
   ],
   "source": [
    "train = neural_network(features=a1a_x_train, result=a1a_y_train, batchsize=20, h1=13, num_hidden_layers=1)\n",
    "train.fit(num_iterations = 100, learning_rate = 0.01, stifle = True)\n",
    "train.predict(a1a_x_test,a1a_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Train and Test Neural Network with 2 Hidden-Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network with 2 Hidden-Layers Prediction\n",
      "\n",
      "MSE:  0.053\n",
      "Mean Absolute Error:  0.216\n",
      "269 / 321  predicted correctly ->  83.8 % accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.05946836, 0.06530213, 0.52400793, 0.02573309, 0.05977396,\n",
       "       0.03285443, 0.03523158, 0.16419985, 0.20845284, 0.02759085,\n",
       "       0.28250217, 0.04652   , 0.09688343, 0.02936442, 0.80070116,\n",
       "       0.39837617, 0.30744115, 0.41437255, 0.02670354, 0.03266903,\n",
       "       0.62019784, 0.19352364, 0.06059123, 0.03046259, 0.37986079,\n",
       "       0.23768813, 0.04272216, 0.15435943, 0.02668232, 0.28563277,\n",
       "       0.28173459, 0.08614673, 0.19054602, 0.04601018, 0.07170828,\n",
       "       0.1911843 , 0.03825208, 0.33709658, 0.19436484, 0.03773154,\n",
       "       0.02946099, 0.03170569, 0.02623537, 0.03551721, 0.2411004 ,\n",
       "       0.03399372, 0.04057315, 0.03940577, 0.11254694, 0.39556085,\n",
       "       0.06151516, 0.04619945, 0.62069425, 0.04095179, 0.07723804,\n",
       "       0.20966108, 0.29178431, 0.8558893 , 0.87279071, 0.55570535,\n",
       "       0.52014021, 0.08755416, 0.264792  , 0.33032978, 0.60655453,\n",
       "       0.09893384, 0.06812367, 0.623975  , 0.07071352, 0.02695892,\n",
       "       0.09535574, 0.71846294, 0.76557469, 0.44661018, 0.03042855,\n",
       "       0.08717746, 0.03476303, 0.07561285, 0.03775378, 0.40391354,\n",
       "       0.03326802, 0.78779943, 0.02766355, 0.24732945, 0.03734163,\n",
       "       0.03670983, 0.03356641, 0.0394436 , 0.06522174, 0.03340185,\n",
       "       0.11159719, 0.0753691 , 0.04195106, 0.0278462 , 0.03547498,\n",
       "       0.33777216, 0.57233814, 0.33654763, 0.25740253, 0.51353312,\n",
       "       0.03783087, 0.30604467, 0.03584461, 0.05405969, 0.04606645,\n",
       "       0.05245523, 0.0442178 , 0.03961849, 0.03745881, 0.14519221,\n",
       "       0.04795914, 0.04566973, 0.06459691, 0.06858295, 0.20284209,\n",
       "       0.04469121, 0.06992825, 0.84608128, 0.27300225, 0.03596912,\n",
       "       0.03621703, 0.86343071, 0.08696497, 0.25449857, 0.68769279,\n",
       "       0.02680704, 0.28029479, 0.72941395, 0.03233663, 0.23430337,\n",
       "       0.02907157, 0.1223916 , 0.62716675, 0.0558971 , 0.48594621,\n",
       "       0.27384059, 0.49789628, 0.04647456, 0.06419066, 0.75008082,\n",
       "       0.22393359, 0.05760748, 0.332041  , 0.14785613, 0.05060548,\n",
       "       0.03005013, 0.02876459, 0.05456701, 0.76355549, 0.03262931,\n",
       "       0.401671  , 0.08918979, 0.03155446, 0.10975058, 0.0634591 ,\n",
       "       0.20168679, 0.14251586, 0.0380983 , 0.08322368, 0.04024084,\n",
       "       0.15055222, 0.16865718, 0.31078458, 0.02832332, 0.02956233,\n",
       "       0.02685049, 0.02792927, 0.03469391, 0.51471001, 0.05409106,\n",
       "       0.08638922, 0.02811409, 0.07450642, 0.06309078, 0.15526103,\n",
       "       0.8938283 , 0.0320182 , 0.03177828, 0.03409009, 0.07154975,\n",
       "       0.17544166, 0.38882779, 0.052418  , 0.0362893 , 0.06309923,\n",
       "       0.03349658, 0.6031822 , 0.75113318, 0.03195514, 0.47314891,\n",
       "       0.63640606, 0.02728386, 0.06572345, 0.0430772 , 0.04935155,\n",
       "       0.08356485, 0.0438453 , 0.69541313, 0.05760748, 0.33033321,\n",
       "       0.0420395 , 0.8199341 , 0.0604811 , 0.03728999, 0.03470717,\n",
       "       0.10059793, 0.57475502, 0.33599106, 0.03007941, 0.85961199,\n",
       "       0.7077253 , 0.03061579, 0.16501237, 0.07254258, 0.8227632 ,\n",
       "       0.29733823, 0.71319735, 0.03627059, 0.03898579, 0.0295346 ,\n",
       "       0.04725699, 0.15083282, 0.16916149, 0.2582635 , 0.035022  ,\n",
       "       0.26451616, 0.03409448, 0.03894085, 0.1074638 , 0.58703489,\n",
       "       0.03719734, 0.02928212, 0.85918524, 0.41704782, 0.13461435,\n",
       "       0.02661511, 0.03614859, 0.34916513, 0.04690901, 0.28582047,\n",
       "       0.04016493, 0.06217101, 0.79289194, 0.05403506, 0.29738297,\n",
       "       0.09862746, 0.37927958, 0.36504566, 0.36877133, 0.77043989,\n",
       "       0.21413161, 0.30744115, 0.88241002, 0.07743681, 0.0306337 ,\n",
       "       0.16419867, 0.0362744 , 0.08782683, 0.15086264, 0.032563  ,\n",
       "       0.03120971, 0.31421482, 0.24749474, 0.05118496, 0.1100403 ,\n",
       "       0.07484117, 0.14929768, 0.76451763, 0.50639142, 0.02478663,\n",
       "       0.18040422, 0.03835201, 0.03406822, 0.22392337, 0.38816999,\n",
       "       0.04016506, 0.03154671, 0.47694506, 0.03861472, 0.03255885,\n",
       "       0.02856543, 0.08331249, 0.51353312, 0.03314104, 0.04903295,\n",
       "       0.04619212, 0.05291659, 0.82077365, 0.0323212 , 0.36381483,\n",
       "       0.10632342, 0.34730927, 0.03293554, 0.03006428, 0.42534748,\n",
       "       0.84655806, 0.08171165, 0.14057197, 0.62571541, 0.64791698,\n",
       "       0.08660288, 0.09228962, 0.89523562, 0.07332796, 0.02693807,\n",
       "       0.17423949, 0.034275  , 0.03838053, 0.03579459, 0.62367125,\n",
       "       0.08250443, 0.08483841, 0.33641324, 0.05116455, 0.41124612,\n",
       "       0.02661338, 0.66461824, 0.42069539, 0.67618548, 0.0456647 ,\n",
       "       0.18437263])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = neural_network(features=a1a_x_train, result=a1a_y_train, batchsize=20, h1=13, h2=5, num_hidden_layers=2)\n",
    "train2.fit(num_iterations = 100, learning_rate = 0.01, stifle = True)\n",
    "train2.predict(a1a_x_test,a1a_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Demonstrate Grid Search Implementation with One-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batchsize</th>\n",
       "      <th># Iterations</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th># Hidden Layer Nodes</th>\n",
       "      <th># Correct</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>70</td>\n",
       "      <td>250</td>\n",
       "      <td>0.014</td>\n",
       "      <td>20</td>\n",
       "      <td>275</td>\n",
       "      <td>85.669782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>0.100</td>\n",
       "      <td>15</td>\n",
       "      <td>275</td>\n",
       "      <td>85.669782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>55</td>\n",
       "      <td>250</td>\n",
       "      <td>0.018</td>\n",
       "      <td>15</td>\n",
       "      <td>275</td>\n",
       "      <td>85.669782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>0.018</td>\n",
       "      <td>15</td>\n",
       "      <td>274</td>\n",
       "      <td>85.358255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>70</td>\n",
       "      <td>150</td>\n",
       "      <td>0.018</td>\n",
       "      <td>15</td>\n",
       "      <td>274</td>\n",
       "      <td>85.358255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>105</td>\n",
       "      <td>50</td>\n",
       "      <td>0.100</td>\n",
       "      <td>10</td>\n",
       "      <td>274</td>\n",
       "      <td>85.358255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>90</td>\n",
       "      <td>250</td>\n",
       "      <td>0.012</td>\n",
       "      <td>15</td>\n",
       "      <td>274</td>\n",
       "      <td>85.358255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>0.018</td>\n",
       "      <td>10</td>\n",
       "      <td>274</td>\n",
       "      <td>85.358255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>0.018</td>\n",
       "      <td>10</td>\n",
       "      <td>274</td>\n",
       "      <td>85.358255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>65</td>\n",
       "      <td>250</td>\n",
       "      <td>0.014</td>\n",
       "      <td>20</td>\n",
       "      <td>274</td>\n",
       "      <td>85.358255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Batchsize  # Iterations  Learning Rate  # Hidden Layer Nodes  # Correct  \\\n",
       "1079         70           250          0.014                    20        275   \n",
       "1813        110            50          0.100                    15        275   \n",
       "787          55           250          0.018                    15        275   \n",
       "61           20           150          0.018                    15        274   \n",
       "1051         70           150          0.018                    15        274   \n",
       "1713        105            50          0.100                    10        274   \n",
       "1471         90           250          0.012                    15        274   \n",
       "1149         75           150          0.018                    10        274   \n",
       "1842        110           150          0.018                    10        274   \n",
       "980          65           250          0.014                    20        274   \n",
       "\n",
       "       Accuracy  \n",
       "1079  85.669782  \n",
       "1813  85.669782  \n",
       "787   85.669782  \n",
       "61    85.358255  \n",
       "1051  85.358255  \n",
       "1713  85.358255  \n",
       "1471  85.358255  \n",
       "1149  85.358255  \n",
       "1842  85.358255  \n",
       "980   85.358255  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_vector = np.arange(20,120,5)#20 to 100 by 20's, 5 of them\n",
    "ni_vector = np.arange(50,350,100)#50 to 250 by 100's, 3 of them\n",
    "lr_vector = np.asarray((0.001,0.002, 0.004, 0.006, 0.008, 0.01,0.012, 0.014, 0.016, 0.018, 0.1))#11 of them\n",
    "nn_vector = np.asarray((10,15,20))#3 of them\n",
    "#5*3*3*3=135\n",
    "hyper_grid_list = []\n",
    "\n",
    "for k in range(len(bs_vector)):\n",
    "    for l in range(len(ni_vector)):\n",
    "        for m in range(len(lr_vector)):\n",
    "            for n in range(len(nn_vector)):\n",
    "                model = neural_network(a1a_x_train, a1a_y_train, batchsize = bs_vector[k], h1=nn_vector[n])\n",
    "                model.fit(num_iterations = ni_vector[l],learning_rate = lr_vector[m], stifle = True)\n",
    "                model.predict(a1a_x_test,a1a_y_test, stifle = True)\n",
    "                hyper_grid_list.append([bs_vector[k],ni_vector[l],lr_vector[m],nn_vector[n],model.number_correct,model.accuracy])\n",
    "\n",
    "names = [\"Batchsize\", \"# Iterations\", \"Learning Rate\",\"# Hidden Layer Nodes\" ,\"# Correct\", \"Accuracy\"]\n",
    "hyper_grid = pd.DataFrame(hyper_grid_list, columns = names)\n",
    "best_hyper_grid = hyper_grid.sort_values(by=['Accuracy'],ascending=0)\n",
    "best_hyper_grid.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Refine Grid Search with One-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batchsize</th>\n",
       "      <th># Iterations</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th># Hidden Layer Nodes</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>0.015</td>\n",
       "      <td>30</td>\n",
       "      <td>0.056147</td>\n",
       "      <td>85.669782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>0.010</td>\n",
       "      <td>15</td>\n",
       "      <td>0.055004</td>\n",
       "      <td>85.046729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10</td>\n",
       "      <td>0.056808</td>\n",
       "      <td>85.046729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>50</td>\n",
       "      <td>75</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>0.057617</td>\n",
       "      <td>85.046729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>0.056439</td>\n",
       "      <td>84.735202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>0.015</td>\n",
       "      <td>20</td>\n",
       "      <td>0.055702</td>\n",
       "      <td>84.735202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>0.010</td>\n",
       "      <td>30</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>84.735202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>0.015</td>\n",
       "      <td>10</td>\n",
       "      <td>0.056508</td>\n",
       "      <td>84.735202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>40</td>\n",
       "      <td>75</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15</td>\n",
       "      <td>0.055660</td>\n",
       "      <td>84.735202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>40</td>\n",
       "      <td>75</td>\n",
       "      <td>0.010</td>\n",
       "      <td>25</td>\n",
       "      <td>0.054937</td>\n",
       "      <td>84.735202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Batchsize  # Iterations  Learning Rate  # Hidden Layer Nodes       MSE  \\\n",
       "74          50            25          0.015                    30  0.056147   \n",
       "156         60            75          0.010                    15  0.055004   \n",
       "140         60            50          0.010                    10  0.056808   \n",
       "90          50            75          0.005                    10  0.057617   \n",
       "202         70            50          0.010                    20  0.056439   \n",
       "237         70           100          0.015                    20  0.055702   \n",
       "24          40            50          0.010                    30  0.056338   \n",
       "25          40            50          0.015                    10  0.056508   \n",
       "31          40            75          0.005                    15  0.055660   \n",
       "38          40            75          0.010                    25  0.054937   \n",
       "\n",
       "      Accuracy  \n",
       "74   85.669782  \n",
       "156  85.046729  \n",
       "140  85.046729  \n",
       "90   85.046729  \n",
       "202  84.735202  \n",
       "237  84.735202  \n",
       "24   84.735202  \n",
       "25   84.735202  \n",
       "31   84.735202  \n",
       "38   84.735202  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_vector = np.arange(40,80,10)#40 to 70 by 10's, 5 of them\n",
    "ni_vector = np.arange(25,125,25)#25 to 100 by 25's, 4 of them\n",
    "lr_vector = np.asarray((0.005,0.01,0.015))#3 of them\n",
    "nn_vector = np.asarray((10,15,20,25,30))#5 of them\n",
    "#5*4*3*5=300\n",
    "hyper_grid_list = []\n",
    "\n",
    "for k in range(len(bs_vector)):\n",
    "    for l in range(len(ni_vector)):\n",
    "        for m in range(len(lr_vector)):\n",
    "            for n in range(len(nn_vector)):\n",
    "                model = neural_network(a1a_x_train, a1a_y_train, batchsize = bs_vector[k], h1=nn_vector[n])\n",
    "                model.fit(num_iterations = ni_vector[l],learning_rate = lr_vector[m], stifle = True)\n",
    "                model.predict(a1a_x_test,a1a_y_test, stifle = True)\n",
    "                hyper_grid_list.append([bs_vector[k],ni_vector[l],lr_vector[m],nn_vector[n],model.number_correct,model.accuracy])\n",
    "\n",
    "names = [\"Batchsize\", \"# Iterations\", \"Learning Rate\",\"# Hidden Layer Nodes\" ,\"# Correct\", \"Accuracy\"]\n",
    "hyper_grid = pd.DataFrame(hyper_grid_list, columns = names)\n",
    "best_hyper_grid = hyper_grid.sort_values(by=['Accuracy'],ascending=0)\n",
    "best_hyper_grid.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Demonstrate Grid Search Implementation with Two-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batchsize</th>\n",
       "      <th># Iterations</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th># Hidden Layers (1)</th>\n",
       "      <th># Hidden Layers (2)</th>\n",
       "      <th># Correct</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>288</td>\n",
       "      <td>89.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>288</td>\n",
       "      <td>89.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>288</td>\n",
       "      <td>89.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>288</td>\n",
       "      <td>89.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>288</td>\n",
       "      <td>89.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>287</td>\n",
       "      <td>89.408100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>287</td>\n",
       "      <td>89.408100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>287</td>\n",
       "      <td>89.408100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>0.01</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>286</td>\n",
       "      <td>89.096573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>286</td>\n",
       "      <td>89.096573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>286</td>\n",
       "      <td>89.096573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>286</td>\n",
       "      <td>89.096573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>286</td>\n",
       "      <td>89.096573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>286</td>\n",
       "      <td>89.096573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>286</td>\n",
       "      <td>89.096573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>286</td>\n",
       "      <td>89.096573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>286</td>\n",
       "      <td>89.096573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>286</td>\n",
       "      <td>89.096573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>286</td>\n",
       "      <td>89.096573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>286</td>\n",
       "      <td>89.096573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Batchsize  # Iterations  Learning Rate  # Hidden Layers (1)  \\\n",
       "721        100           100           0.01                   20   \n",
       "707        100           100           0.01                   11   \n",
       "709        100           100           0.01                   11   \n",
       "414         60           100           0.01                   14   \n",
       "712        100           100           0.01                   14   \n",
       "409         60           100           0.01                   11   \n",
       "674        100            50           0.10                   20   \n",
       "722        100           100           0.01                   20   \n",
       "492         60           150           0.01                   17   \n",
       "779        100           150           0.01                    8   \n",
       "402         60           100           0.01                    8   \n",
       "497         60           150           0.01                   20   \n",
       "784        100           150           0.01                   11   \n",
       "419         60           100           0.01                   17   \n",
       "486         60           150           0.01                   14   \n",
       "723        100           100           0.01                   20   \n",
       "183         20           150           0.01                   11   \n",
       "412         60           100           0.01                   14   \n",
       "406         60           100           0.01                   11   \n",
       "361         60            50           0.10                   14   \n",
       "\n",
       "     # Hidden Layers (2)  # Correct   Accuracy  \n",
       "721                   11        288  89.719626  \n",
       "707                   14        288  89.719626  \n",
       "709                   20        288  89.719626  \n",
       "414                   20        288  89.719626  \n",
       "712                   14        288  89.719626  \n",
       "409                   20        287  89.408100  \n",
       "674                   20        287  89.408100  \n",
       "722                   14        287  89.408100  \n",
       "492                   14        286  89.096573  \n",
       "779                   20        286  89.096573  \n",
       "402                   14        286  89.096573  \n",
       "497                   14        286  89.096573  \n",
       "784                   20        286  89.096573  \n",
       "419                   20        286  89.096573  \n",
       "486                   11        286  89.096573  \n",
       "723                   17        286  89.096573  \n",
       "183                   17        286  89.096573  \n",
       "412                   14        286  89.096573  \n",
       "406                   11        286  89.096573  \n",
       "361                   11        286  89.096573  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_vector = np.arange(20,140,40)#20 to 100 by 40's, 3 of them\n",
    "ni_vector = np.arange(50,250,50)#50 to 200 by 50's, 4 of them\n",
    "lr_vector = np.asarray((0.001, 0.01, 0.1))#3 of them\n",
    "nn1_vector = np.arange(8,23,3)#8 to 20 by 3's, 5 of them\n",
    "nn2_vector = np.arange(8,23,3)#8 to 20 by 3's, 5 of them\n",
    "#3*4*3*5*5=1296\n",
    "hyper_grid_list = []\n",
    "\n",
    "for k in range(len(bs_vector)):\n",
    "    for l in range(len(ni_vector)):\n",
    "        for m in range(len(lr_vector)):\n",
    "            for n in range(len(nn1_vector)):\n",
    "                for o in range(len(nn2_vector)):\n",
    "                    model = neural_network(a1a_x_train, \n",
    "                                           a1a_y_train, \n",
    "                                           batchsize = bs_vector[k], \n",
    "                                           h1=nn1_vector[n],\n",
    "                                           h2=nn2_vector[o], \n",
    "                                           num_hidden_layers = 2)\n",
    "\n",
    "                    model.fit(num_iterations = ni_vector[l],learning_rate = lr_vector[m], stifle = True)\n",
    "                    model.predict(a1a_x_test,a1a_y_test, stifle = True)\n",
    "                    hyper_grid_list.append([bs_vector[k],ni_vector[l],lr_vector[m],nn1_vector[n],nn2_vector[o],model.number_correct,model.accuracy])\n",
    "\n",
    "names = [\"Batchsize\", \"# Iterations\", \"Learning Rate\",\"# Hidden Layers (1)\",\"# Hidden Layers (2)\",\"# Correct\", \"Accuracy\"]\n",
    "hyper_grid = pd.DataFrame(hyper_grid_list, columns = names)\n",
    "best_hyper_grid = hyper_grid.sort_values(by=['Accuracy'],ascending=0)\n",
    "best_hyper_grid.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Demonstrate Score Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network with 2 Hidden-Layers Prediction\n",
      "\n",
      "MSE:  0.067\n",
      "Mean Absolute Error:  0.250\n",
      "257 / 321  predicted correctly ->  80.1 % accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3293290309317157"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.score(test_x=a1a_x_test,test_y=a1a_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <br>Demonstrate Coefficients Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0 [ 0.11582949 -0.61591208  0.22982466  0.59985338 -1.17224137  1.17458366\n",
      "  0.49430813 -0.57496316 -0.65857368  0.57571618  1.78339198 -2.63364594\n",
      " -1.46736565  0.22604573] \n",
      "\n",
      "W1 [[-0.64138555  1.07071366 -0.45420362  0.00888695  0.49716639  0.70526263\n",
      "  -0.43396605  0.27494407  0.85630112  0.81498079  0.6291566  -2.3740532\n",
      "  -0.86687969]\n",
      " [ 1.04966597 -1.7104155  -1.24695801 -0.75354514  0.17208467  0.60085087\n",
      "   0.62751832 -0.3786915  -1.20164854 -3.10616017 -0.17842662  0.2281082\n",
      "  -0.43174588]\n",
      " [ 0.66502049  0.49928211 -0.02244262 -0.40924094 -0.24265066  0.58764316\n",
      "  -0.16523566 -2.00064669 -0.60104784  0.11797181 -1.45436345  2.03429809\n",
      "  -2.0703829 ]\n",
      " [ 0.21993944 -0.93703406 -0.14210281 -0.84200558  0.08476769  1.25085856\n",
      "  -2.48502369 -1.93949214 -1.66005505  2.34292042 -1.84101317 -0.96986635\n",
      "   0.35724802]\n",
      " [-0.32293952  0.13049623 -1.5481438   0.31587853 -1.75552459  0.94540566\n",
      "  -0.44612431  1.0742524  -1.37375964  0.97475448  2.40698834  1.99219374\n",
      "   0.12445939]\n",
      " [ 1.71737357 -0.0200145  -1.07844016  1.93712743  0.05823307  0.17451944\n",
      "   0.04561906 -1.26167804  0.01125815  0.36468495  0.43091824 -0.34121855\n",
      "  -0.48106682]] \n",
      "\n",
      "W2 [[-1.02569016e+00 -1.72766279e+00 -7.66302187e-01  2.36459215e+00\n",
      "  -1.33804264e+00]\n",
      " [-2.32636690e-01  8.05156535e-01  9.30396433e-02  7.06638615e-01\n",
      "   5.16964825e-01]\n",
      " [ 6.15882245e-01  1.55422246e+00 -2.26223457e-01  7.77030886e-01\n",
      "  -7.96368147e-03]\n",
      " [-5.46514517e-02 -7.47115421e-01  1.54878130e+00  3.63949827e-01\n",
      "  -4.50068679e-01]\n",
      " [-6.63482186e-01  3.67489098e-01  7.72645600e-01 -1.28452424e+00\n",
      "   3.63361105e-01]\n",
      " [-1.12981543e+00  1.29017502e-05  1.91789937e-01 -7.21825378e-01\n",
      "  -1.03701153e+00]\n",
      " [ 2.09681334e-01  1.14350073e+00  4.54636429e-01 -3.90142484e-02\n",
      "   1.34579644e+00]\n",
      " [ 5.10804712e-01 -1.11826993e+00  1.10824727e-01  1.02427656e+00\n",
      "   6.84974379e-02]\n",
      " [ 2.01303370e-01  6.72134287e-01  1.88285614e+00  8.88309639e-01\n",
      "   1.02538400e+00]\n",
      " [-6.48476676e-01  8.39505805e-02  8.06088403e-02 -8.59671630e-01\n",
      "  -1.87594948e-01]\n",
      " [-1.37403199e+00  2.71813655e-01 -2.02238655e+00 -9.02542469e-01\n",
      "   4.84799573e-02]\n",
      " [ 2.72963151e-01  5.34441509e-01 -8.24301925e-02  8.59026180e-02\n",
      "   1.05401949e+00]\n",
      " [-2.03462447e+00 -1.91587791e-02 -3.40349506e-01  6.79680847e-01\n",
      "   2.68195423e+00]\n",
      " [ 5.49282804e-01 -6.85599053e-01 -7.60314312e-01 -4.12517003e-01\n",
      "   4.05018092e-01]\n",
      " [ 2.39899268e-02  1.14194286e+00 -9.83794398e-01  2.20141994e+00\n",
      "   8.40303574e-01]\n",
      " [ 1.33769908e-01 -4.57694960e-01 -5.81361068e-01  5.58755811e-01\n",
      "   1.12073472e+00]\n",
      " [ 5.76867912e-01  6.13676130e-01 -1.40503663e+00 -2.62897523e-01\n",
      "   1.76962921e+00]\n",
      " [ 5.56064953e-01 -2.95658226e-01 -1.26203340e+00  4.48409599e-01\n",
      "  -6.18325676e-01]\n",
      " [ 2.35718315e+00  2.29029886e-01 -1.64301404e+00 -4.25182231e-01\n",
      "  -1.35048303e+00]\n",
      " [-1.33417268e-01  9.19182242e-02 -1.51752745e+00 -2.17550035e+00\n",
      "  -7.79827644e-01]\n",
      " [ 1.02364210e-01  3.67261649e-02  6.42191186e-01  5.31740193e-01\n",
      "   2.81701329e-01]\n",
      " [ 4.55529122e-01 -3.88376632e-01 -9.56260963e-01  9.42174513e-01\n",
      "   1.18099456e+00]\n",
      " [ 2.38130086e-01 -7.63826891e-01  3.18858012e-01  1.24474084e+00\n",
      "  -1.09876117e+00]\n",
      " [ 7.47017644e-01  1.17433103e+00  2.20511397e-01  8.55570964e-01\n",
      "  -1.60896353e+00]\n",
      " [ 8.31442291e-01 -5.74046013e-01  2.87760563e-02  9.52737050e-01\n",
      "   6.05123223e-01]\n",
      " [ 1.90329898e-01 -5.38593375e-01 -9.48591542e-01 -1.85149285e+00\n",
      "   8.40095903e-01]\n",
      " [-6.47877041e-01 -1.27333197e+00  2.13669108e-01 -3.21844460e-01\n",
      "   1.00364629e-01]\n",
      " [ 1.26137237e+00 -7.45515321e-01 -7.09510791e-01  6.29982669e-01\n",
      "  -1.56268389e+00]\n",
      " [ 5.31658887e-01 -4.89346574e-01  1.31804039e+00 -6.88056455e-01\n",
      "  -1.36267374e+00]\n",
      " [-4.87205231e-01  5.28546494e-01  9.29176516e-01 -1.13522699e+00\n",
      "  -5.69446267e-01]\n",
      " [-1.57111596e+00  4.81975609e-02  8.41410742e-01 -6.92956979e-01\n",
      "   9.77524189e-01]\n",
      " [ 2.09572690e+00 -6.23429207e-01 -4.77640085e-01  2.53209206e-01\n",
      "   6.78760676e-01]\n",
      " [-6.18432919e-01  8.19647775e-01  2.02675457e+00 -2.05423420e+00\n",
      "  -1.27378717e+00]\n",
      " [-2.84230824e-01 -1.05183663e+00 -1.01282371e+00 -5.71001786e-01\n",
      "  -9.98090807e-01]\n",
      " [ 1.99865525e-01 -8.24967265e-01  1.05858233e+00 -7.52005257e-01\n",
      "  -1.31858501e-02]\n",
      " [-1.29534436e-01 -8.88144882e-02 -8.39826862e-01  9.98526322e-01\n",
      "   1.29041995e+00]\n",
      " [ 2.25331224e-01 -1.49225088e+00 -9.55051671e-01 -2.07506414e+00\n",
      "   2.88520756e-01]\n",
      " [-2.90404984e-01  6.60555839e-01 -3.15014602e-01 -1.16111687e+00\n",
      "   3.61640157e-01]\n",
      " [ 3.96772840e-01  1.94502765e-01  1.98613899e+00  4.85201430e-01\n",
      "  -2.13093000e-01]\n",
      " [-2.45162478e-01  3.63117984e-01  1.56679315e+00 -1.10870027e+00\n",
      "  -7.86273594e-01]\n",
      " [-1.40915074e+00  9.67206322e-01  2.21204177e-01 -5.59750403e-01\n",
      "   1.20276496e-02]\n",
      " [ 1.11783472e+00 -6.15458639e-01 -1.48200772e+00 -8.22496261e-01\n",
      "   7.05358317e-01]\n",
      " [ 1.57758700e+00  5.62732300e-01 -8.55982438e-01  1.19776518e+00\n",
      "   9.43232449e-01]\n",
      " [-6.95507816e-02 -1.23641007e+00 -5.60954667e-01 -3.27648093e-02\n",
      "  -7.60021137e-01]\n",
      " [ 1.06139644e+00  8.00300896e-01 -6.64533436e-01  1.39395950e+00\n",
      "   2.58640179e+00]\n",
      " [ 1.46328109e+00  5.69107954e-01  4.88007285e-02  9.84869068e-01\n",
      "  -1.10492651e+00]\n",
      " [-3.74754862e-01 -1.31759388e-01 -1.52031467e-01  7.58731586e-01\n",
      "   1.45724437e-01]\n",
      " [-2.83465812e-01  2.32204793e+00 -4.14941994e-02 -1.02018097e+00\n",
      "   1.88844745e+00]\n",
      " [ 1.65124063e-01 -1.44745818e-01 -2.97233924e-01  2.66438111e-01\n",
      "   1.51968189e+00]\n",
      " [ 2.41299574e-01 -1.56667334e+00  7.11221479e-01  1.79626128e+00\n",
      "   1.19902912e+00]\n",
      " [ 1.18042664e+00  1.87732413e+00 -2.36397623e-01  1.63700623e-01\n",
      "   1.43956189e-01]\n",
      " [-7.23642692e-01 -2.30235750e-01  1.89601031e+00 -6.21613101e-01\n",
      "  -3.91548251e-01]\n",
      " [ 8.22320120e-01  7.75925149e-01  1.01253443e-01 -1.90833750e-01\n",
      "  -1.61845107e+00]\n",
      " [-7.00228667e-01  3.05459298e-01 -7.20892069e-01 -2.51545864e+00\n",
      "   1.51781004e+00]\n",
      " [ 7.49691744e-02 -2.40301025e+00 -4.21854138e-01  9.27277155e-02\n",
      "  -1.43483174e-01]\n",
      " [-7.27556304e-01  2.67547982e+00  7.87697615e-01 -1.51565741e-01\n",
      "  -1.86204897e+00]\n",
      " [ 8.69312687e-01 -8.01124896e-01 -2.23307278e-01  4.06439275e-01\n",
      "  -1.17313494e+00]\n",
      " [-6.86056337e-01  1.01478726e+00  6.87090058e-03  6.73211333e-01\n",
      "  -1.30056861e-01]\n",
      " [-2.15776582e+00  1.83476976e+00  5.70335770e-01  7.42306579e-02\n",
      "  -1.33148335e+00]\n",
      " [-1.30143658e+00  7.38543166e-01  8.89683578e-02 -1.01997679e+00\n",
      "   9.16776095e-01]\n",
      " [ 8.71077891e-01  1.19777190e+00  8.78860187e-01 -4.94048433e-02\n",
      "   4.84694714e-02]\n",
      " [ 1.00642251e-01  4.57682341e-01  1.79475175e+00 -1.28020151e+00\n",
      "  -5.06975035e-01]\n",
      " [-2.85274933e-01 -9.27511984e-01 -2.28565537e+00  2.16685169e-01\n",
      "  -3.60494306e+00]\n",
      " [ 4.26263839e-01 -6.42304171e-01  2.38100362e-01 -8.41155488e-01\n",
      "  -6.95513178e-01]\n",
      " [-3.14854045e-01 -2.43942531e+00 -2.60655579e+00 -2.24145609e-01\n",
      "   1.11064095e-02]\n",
      " [-1.53939115e+00  4.27245179e-01  1.04407226e+00 -2.96283282e-01\n",
      "   4.20835276e-01]\n",
      " [ 1.73292366e+00  1.27964294e+00 -1.21780674e-01 -1.37109699e+00\n",
      "   8.86801316e-01]\n",
      " [ 1.09543237e+00 -7.67274329e-01  4.89468265e-01 -1.72591655e+00\n",
      "   2.79027413e-01]\n",
      " [-1.43415353e+00  5.81969077e-01 -2.47876096e-01 -1.12390196e+00\n",
      "   5.54763497e-01]\n",
      " [-2.24780169e+00 -1.04488291e+00  1.70298883e+00  4.47397328e-01\n",
      "   8.27875864e-01]\n",
      " [ 5.65699152e-01  2.16547033e+00  9.11950098e-02  3.51537231e-01\n",
      "  -7.06945170e-01]\n",
      " [ 3.78254268e-01 -2.18803623e-02 -3.22416624e-01  6.25992970e-01\n",
      "   4.17853903e-01]\n",
      " [-8.21926455e-01  1.13808620e-01 -7.75204002e-01  1.36075656e-01\n",
      "   5.44759324e-01]\n",
      " [-7.81468161e-02 -1.11880854e+00  3.45580378e-01 -1.06397754e+00\n",
      "  -2.16959056e+00]\n",
      " [ 8.14840636e-01  1.11955434e+00 -5.90642819e-01  1.09798487e+00\n",
      "   9.93886713e-01]\n",
      " [-1.98520170e-01 -8.75818638e-01  1.76265573e-01 -7.52678773e-01\n",
      "   4.40434034e-01]\n",
      " [ 8.88096612e-01  7.60186366e-02  6.84667962e-02  7.21547881e-01\n",
      "   1.07317525e+00]\n",
      " [-1.34576571e+00  1.11428489e+00  5.33661152e-01 -3.13509125e-01\n",
      "   1.05454531e+00]\n",
      " [ 8.57910923e-01 -2.20093794e-01 -3.22165779e-01  2.02053144e+00\n",
      "  -8.75651753e-02]\n",
      " [ 9.61217327e-02  1.60708836e-01  1.23563793e+00  7.35504493e-01\n",
      "   6.57664738e-01]\n",
      " [-9.36494207e-01  3.19261954e+00 -4.12128911e-02  1.15129679e+00\n",
      "   1.59796496e+00]\n",
      " [ 3.68163595e-01 -4.72205875e-01  4.03740555e-01 -1.08965425e+00\n",
      "   7.46375422e-01]\n",
      " [ 4.50509977e-01  4.69903088e-01  1.73642401e-01  4.02451489e-01\n",
      "  -1.16750991e+00]\n",
      " [ 1.45158040e-01  5.69770022e-01  4.54175573e-01 -3.88764730e-01\n",
      "   6.41808536e-01]\n",
      " [ 5.16905927e-01 -2.82267659e-01  3.56807301e-01  1.19227298e+00\n",
      "  -4.06571538e-01]\n",
      " [ 2.44795141e+00  1.74097887e+00 -1.02016922e+00 -2.72191645e+00\n",
      "  -1.03790061e+00]\n",
      " [ 1.34040479e-01  1.75286249e+00  1.29909571e+00  2.17793092e+00\n",
      "   4.35516388e-01]\n",
      " [ 6.05803264e-01 -7.85323520e-01  4.91032988e-01 -5.80865856e-02\n",
      "   1.41519979e+00]\n",
      " [-7.52050541e-02 -2.24772595e-01  1.80221758e-01 -8.05119655e-01\n",
      "  -1.71407024e+00]\n",
      " [ 1.10785646e+00  7.41495039e-01  1.05466689e+00 -2.68835754e-01\n",
      "  -3.48340066e-01]\n",
      " [ 1.46478043e-01 -2.35907650e+00  5.86713343e-01 -6.25590765e-01\n",
      "   3.77684858e-02]\n",
      " [ 4.82803914e-01 -8.20745709e-03 -2.72266645e-01 -4.24794314e-01\n",
      "  -6.19631703e-01]\n",
      " [ 3.48110719e-01  1.21456779e+00  1.39091970e+00 -5.54657125e-01\n",
      "  -3.39542013e+00]\n",
      " [-1.84742704e-01 -2.49308928e-01 -4.64310499e-01 -9.34941760e-01\n",
      "  -1.29440345e+00]\n",
      " [ 1.98586919e-01  1.07863059e+00 -7.35377055e-01  7.92172941e-01\n",
      "   1.28377871e+00]\n",
      " [-1.28428094e+00 -3.40260121e-02 -1.41478946e+00  1.46357756e+00\n",
      "  -2.19210069e-01]\n",
      " [-1.41576113e+00  1.83433216e+00  2.42318456e-01 -1.58336891e+00\n",
      "   8.19459520e-01]\n",
      " [-1.33792234e-02 -1.72248610e+00  1.24701203e+00 -3.65137262e-01\n",
      "   8.23333564e-01]\n",
      " [-4.77837596e-02  1.22330886e+00 -9.53342610e-01  1.74535375e+00\n",
      "   5.12532026e-01]\n",
      " [-7.81860995e-01 -7.60455570e-01 -3.96341088e-01  5.29807207e-01\n",
      "   1.20107326e+00]\n",
      " [-3.59413745e-01 -1.22009577e-01 -7.19805973e-01 -1.33157679e+00\n",
      "  -6.50786690e-01]\n",
      " [-1.23423037e+00 -9.14727908e-01  7.12796181e-01  1.45214029e+00\n",
      "  -5.48676265e-01]\n",
      " [ 2.26034207e+00 -1.10782861e+00  4.39357029e-01  9.61848660e-01\n",
      "  -7.88054188e-01]\n",
      " [ 1.03188952e+00  1.01684697e+00 -8.47374792e-01 -2.00504793e+00\n",
      "   6.21603273e-01]\n",
      " [ 9.51074463e-01 -2.80514951e-02 -8.70007156e-03 -1.03333879e+00\n",
      "  -9.57144563e-01]\n",
      " [-1.36143848e-01  1.36123903e-01 -7.94078934e-02 -5.48522770e-01\n",
      "   5.93748902e-01]\n",
      " [-1.25212672e+00 -2.06438663e+00 -2.26275305e-01 -8.60098209e-01\n",
      "   8.75592527e-01]\n",
      " [-3.90318354e-01 -2.10637729e+00  7.17476326e-01  1.08460489e+00\n",
      "  -1.73256127e+00]\n",
      " [-4.64370489e-01 -6.89042715e-01 -1.41879280e+00  4.81994612e-01\n",
      "  -1.38885849e+00]\n",
      " [-5.28000451e-01 -6.00221742e-01 -6.92881610e-01 -6.91475979e-01\n",
      "  -1.02055212e+00]\n",
      " [-1.04337847e+00 -6.18821732e-01 -1.89470146e-01 -2.31597779e-01\n",
      "   3.06806340e-01]\n",
      " [ 4.48103150e-01 -1.04992828e-01 -1.75639495e+00 -2.43862282e-01\n",
      "  -5.02975449e-01]\n",
      " [ 9.08236143e-02  1.11783600e-01  1.01432687e+00 -1.69560168e-01\n",
      "  -4.20622612e-01]\n",
      " [ 2.89180386e-01 -8.32325236e-01  1.22051343e+00  2.10829302e-01\n",
      "  -5.93969302e-01]\n",
      " [-1.19861342e+00 -1.81527990e+00  6.06656739e-02 -1.62718081e+00\n",
      "  -3.55470371e-01]\n",
      " [-9.49240894e-01 -1.06489784e+00 -1.32141024e+00  1.08016469e+00\n",
      "   1.30750688e+00]\n",
      " [ 1.32078546e-01  7.38906512e-01 -2.53504106e-01  2.69302040e-01\n",
      "   3.19574802e-01]\n",
      " [ 1.68287639e+00 -1.02766422e-01  4.25410748e-01 -1.18992230e+00\n",
      "   6.90424622e-01]\n",
      " [ 7.67135073e-01 -8.09330940e-01  6.28373022e-01  2.91038136e+00\n",
      "   1.78788851e+00]\n",
      " [ 3.17209682e-01 -1.82599897e-01 -1.28847561e+00  6.76484670e-01\n",
      "  -9.38834700e-01]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train2.coef()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
